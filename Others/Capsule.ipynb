{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capsule\n",
    "\n",
    "核心思想是： 每个capsule代表一个特征。\n",
    "\n",
    "具体的解释，请看 [揭开迷雾，来一顿美味的Capsule盛宴 By 苏剑林](https://kexue.fm/archives/4819)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, in_cap_num, in_dim, out_cap_num, out_dim, routings):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "        self.out_cap_num = out_cap_num # 下一层 capsule 的个数\n",
    "        self.in_cap_num = in_cap_num\n",
    "        self.routings = routings\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        # 变换矩阵\n",
    "        self.W = nn.Parameter(torch.randn(in_cap_num, out_cap_num, out_dim, in_dim)) # \n",
    "        \n",
    "    def forward(self, u_vecs):\n",
    "        \"\"\"\n",
    "            考虑简单情况，每次都是一个样本，也就是说，我们的输入 u_vecs 是 (in_capsule_num, capsule_dim)\n",
    "        \"\"\"        \n",
    "        # 完成变换矩阵\n",
    "        \n",
    "        b = Variable(torch.zeros(self.out_cap_num, self.in_cap_num))\n",
    "        u_hat = Variable(torch.zeros((self.out_cap_num, self.in_cap_num, self.out_dim)))\n",
    "        \n",
    "        for j in range(self.out_cap_num):\n",
    "            for i in range(self.in_cap_num):\n",
    "                u_hat[j, i] = torch.mm(self.W[i, j], u_vecs[i].view(-1,1))\n",
    "        # dynamic routing\n",
    "        for i in range(self.routings):\n",
    "            c = F.softmax(b, dim=1) # num_capsule * input_capsule_num (表示概率)\n",
    "            s = torch.matmul(c.unsqueeze_(1), u_hat).squeeze_(1) # out_cap_num*out_dim\n",
    "            v = self.squash(s)\n",
    "            b = b + torch.matmul(u_hat, v.unsqueeze(2)).squeeze_(2)\n",
    "        return v\n",
    "\n",
    "    # 定义 squash 函数\n",
    "    @staticmethod\n",
    "    def squash(x, p=2, dim=1, keepdim=True):\n",
    "        \"\"\"\n",
    "            params: x (num*feature), p: 几范数, dim: 对哪个维度求范数, keepdim: 保持维度一致\n",
    "            return: squash_x (b*m)\n",
    "        \"\"\"\n",
    "        squash_norm = torch.norm(x, p, dim, keepdim)\n",
    "        scale = torch.sqrt(squash_norm) / (1 + squash_norm)\n",
    "        return scale * x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u[5*128] v[4*16]\n",
    "cap = CapsuleLayer(5, 128, 4, 16, 3)\n",
    "\n",
    "u_vecs = Variable(torch.randn((5, 128)))\n",
    "\n",
    "vttt = cap(u_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑例子中的情况\n",
    "# u[5*128] v[4*16]\n",
    "\n",
    "u = Variable(torch.randn((5, 128)))\n",
    "\n",
    "W = Variable(torch.randn((5, 4, 16, 128)))\n",
    "\n",
    "b = Variable(torch.zeros((4, 5)))\n",
    "\n",
    "u_hat = Variable(torch.zeros((4, 5, 16)))\n",
    "\n",
    "for j in range(4):\n",
    "    for i in range(5):\n",
    "        u_hat[j, i] = torch.mm(W[i, j], u[i].view(-1,1))\n",
    "\n",
    "for r in range(3):\n",
    "    c = F.softmax(b, dim=1)\n",
    "    s = torch.matmul(c.unsqueeze_(1), u_hat).squeeze_(1) # 4*16\n",
    "    v = squash(s) # 4*16\n",
    "    b = b + torch.matmul(u_hat, v.unsqueeze(2)).squeeze_(2)\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

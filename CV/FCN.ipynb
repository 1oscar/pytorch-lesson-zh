{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用FCN来完成语义分割任务\n",
    "\n",
    "\n",
    "## 1. 什么是语义分割?\n",
    "\n",
    "语义分割指的是**像素级别**地识别图片,标注出图像中每个像素属于的对象类别.\n",
    "\n",
    "比如这张经典的图片!\n",
    "\n",
    "![example1](./images/fcn_example.png)\n",
    "\n",
    "我们除了识别出自行车和人之外,我们还将他们的边界也进行了描绘.\n",
    "\n",
    "所以**语义分割可以看做对每一个像素进行分类**\n",
    "\n",
    "\n",
    "## 2. FCN的简单介绍\n",
    "\n",
    "为什么要叫 FCN(Fully Convolutional Networks) 呢?\n",
    "\n",
    "因为在以前的任务中(2015年之前)使用CNN更多地是在卷积层之后会接上若干个全连接层, 将卷积层产生的特征图(feature map)映射成一个固定长度的特征向量（这就丢失了空间信息）。以AlexNet为代表的经典CNN结构适合于图像级的分类和回归任务，因为它们最后都期望得到整个输入图像的一个数值描述（概率），比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。\n",
    "\n",
    "但是 FCN 不同, FCN对图像进行像素级的分类，从而解决了语义级别的图像分割（semantic segmentation）问题。与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，**FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸**，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。\n",
    "\n",
    "\n",
    "总结一下就是:\n",
    "\n",
    "**CNN的输入是图像，输出是一个结果，或者说是一个值，一个概率值。**\n",
    "\n",
    "**FCN提出所追求的是，输入是一张图片是，输出也是一张图片，学习像素到像素的映射 。**\n",
    "\n",
    "这样的特征刚好符合语义分割任务中的,对像素进行分类.\n",
    "\n",
    "## 3. FCN的网络架构\n",
    "\n",
    "\n",
    "![network](./images/FCN_network.png)\n",
    "\n",
    "\n",
    "整个模型是 end-to-end 的.\n",
    "\n",
    "具体的流程是: 先**降采样（卷积、池化）**，再**上采样（反卷积）**\n",
    "\n",
    "降采样是为了更好的获得语义信息(因为不多用几层卷积就没法正确分类)。\n",
    "\n",
    "但是卷积和池化之后feature map变的很小了，需要还原成原图大小，所以就用上采样（反卷积）的方式把feature map 还原回原图大小。\n",
    "\n",
    "\n",
    "## 4. FCN中的关键技术\n",
    "\n",
    "### 4.1 反卷积(Deconvolution) 或者 转置卷积(conv_transpose)\n",
    "\n",
    "两者其实是等价的,只是称呼上有差异.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as tfs\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据路径\n",
    "voc_root = 'XXX'\n",
    "def read_images(root=voc_root, train=True):\n",
    "    txt_fname = root + '/ImageSets/Segmentation/' + ('train.txt' if train else 'val.txt')\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    data = [os.path.join(root, 'JPEGImages', i+'.jpg') for i in images]\n",
    "    label = [os.path.join(root, 'SegmentationClass', i+'.png') for i in images]\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#等比例压缩图片\n",
    "def scale_high(img, target_high):\n",
    "    ow, oh = img.size\n",
    "    if (ow == target_high):\n",
    "        return img\n",
    "    h = target_high\n",
    "    w = int(target_high * ow / oh)\n",
    "    return img.resize((w, h), Image.BICUBIC)\n",
    "\n",
    "#中心裁剪\n",
    "def random_crop(data, label, crop_size):\n",
    "    transforms = tfs.CenterCrop(crop_size)\n",
    "    data = transforms(data)\n",
    "    label = transforms(label)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['background','aeroplane','bicycle','bird','boat',\n",
    "           'bottle','bus','car','cat','chair','cow','diningtable',\n",
    "           'dog','horse','motorbike','person','potted plant',\n",
    "           'sheep','sofa','train','tv/monitor']\n",
    "\n",
    "colormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,0],[0,64,128]]\n",
    "\n",
    "len(classes), len(colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个像素点有 0 ~ 255 的选择，RGB 三个通道\n",
    "cm2lbl = np.zeros(256**3) \n",
    "for i,cm in enumerate(colormap):\n",
    "    # 建立索引\n",
    "    cm2lbl[(cm[0]*256+cm[1])*256+cm[2]] = i \n",
    "\n",
    "def image2label(img):\n",
    "    data = np.array(img, dtype='int32')\n",
    "    idx = (data[:, :, 0] * 256 + data[:, :, 1]) * 256 + data[:, :, 2]\n",
    "    # 根据索引得到 label 矩阵\n",
    "    return np.array(cm2lbl[idx], dtype='int64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_transforms(img, label, crop_size):\n",
    "    img, label = random_crop(img, label, crop_size)\n",
    "    img = scale_high(img,int(img.size[1]/2))\n",
    "    label = scale_high(label,int(label.size[1]/2))\n",
    "    img_tfs = tfs.Compose([      \n",
    "        tfs.ToTensor(),\n",
    "        tfs.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    img = img_tfs(img)\n",
    "    label = image2label(label)\n",
    "    label = torch.from_numpy(label)\n",
    "    return img, label\n",
    "\n",
    "#制作数据集\n",
    "class VOCSegDataset(Dataset):\n",
    "    def __init__(self, train, crop_size, transforms):\n",
    "        self.crop_size = crop_size\n",
    "        self.transforms = transforms\n",
    "        data_list, label_list = read_images(train=train)\n",
    "        print('Read ' + str(len(self.data_list)) + ' images')\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        img = Image.open(img)\n",
    "        label = Image.open(label).convert('RGB')\n",
    "        img, label = self.transforms(img, label, self.crop_size)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化数据集\n",
    "batch_size = 16\n",
    "input_shape = (512, 512)\n",
    "train_data = VOCSegDataset(True, input_shape, img_transforms)\n",
    "testdata = VOCSegDataset(False, input_shape, img_transforms)\n",
    "trainloader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "testloader = DataLoader(testdata, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#初始化权值\n",
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype=np.float64)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCN网络结构的定义\n",
    "n_class = len(classes)\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, n_class=21):\n",
    "        super(FCN, self).__init__()\n",
    "        # conv1\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "\n",
    "        # conv2\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
    "\n",
    "        # conv3\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
    "\n",
    "        # conv4\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
    "\n",
    "        # conv5\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
    "\n",
    "        # fc6\n",
    "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "\n",
    "        # fc7\n",
    "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "\n",
    "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
    "        self.score_pool3 = nn.Conv2d(256, n_class, 1)\n",
    "        self.score_pool4 = nn.Conv2d(512, n_class, 1)\n",
    "\n",
    "        self.upscore2 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 4, stride=2, bias=False)\n",
    "        self.upscore8 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 16, stride=8, bias=False)\n",
    "        self.upscore_pool4 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 4, stride=2, bias=False)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.zero_()\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = get_upsampling_weight(\n",
    "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                m.weight.data.copy_(initial_weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.relu1_1(self.conv1_1(h))\n",
    "        h = self.relu1_2(self.conv1_2(h))\n",
    "        h = self.pool1(h)\n",
    "\n",
    "        h = self.relu2_1(self.conv2_1(h))\n",
    "        h = self.relu2_2(self.conv2_2(h))\n",
    "        h = self.pool2(h)\n",
    "\n",
    "        h = self.relu3_1(self.conv3_1(h))\n",
    "        h = self.relu3_2(self.conv3_2(h))\n",
    "        h = self.relu3_3(self.conv3_3(h))\n",
    "        h = self.pool3(h)\n",
    "        pool3 = h  # 1/8\n",
    "\n",
    "        h = self.relu4_1(self.conv4_1(h))\n",
    "        h = self.relu4_2(self.conv4_2(h))\n",
    "        h = self.relu4_3(self.conv4_3(h))\n",
    "        h = self.pool4(h)\n",
    "        pool4 = h  # 1/16\n",
    "\n",
    "        h = self.relu5_1(self.conv5_1(h))\n",
    "        h = self.relu5_2(self.conv5_2(h))\n",
    "        h = self.relu5_3(self.conv5_3(h))\n",
    "        h = self.pool5(h)\n",
    "\n",
    "        h = self.relu6(self.fc6(h))\n",
    "        h = self.drop6(h)\n",
    "\n",
    "        h = self.relu7(self.fc7(h))\n",
    "        h = self.drop7(h)\n",
    "\n",
    "        h = self.score_fr(h)\n",
    "        h = self.upscore2(h)\n",
    "        upscore2 = h  # 1/16\n",
    "\n",
    "        h = self.score_pool4(pool4)\n",
    "        h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
    "        score_pool4c = h  # 1/16\n",
    "\n",
    "        h = upscore2 + score_pool4c  # 1/16\n",
    "        h = self.upscore_pool4(h)\n",
    "        upscore_pool4 = h  # 1/8\n",
    "\n",
    "        h = self.score_pool3(pool3)\n",
    "        h = h[:, :,\n",
    "              9:9 + upscore_pool4.size()[2],\n",
    "              9:9 + upscore_pool4.size()[3]]\n",
    "        score_pool3c = h  # 1/8\n",
    "\n",
    "        h = upscore_pool4 + score_pool3c  # 1/8\n",
    "\n",
    "        h = self.upscore8(h)\n",
    "        h = h[:, :, 31:31 + x.size()[2], 31:31 + x.size()[3]].contiguous()\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#模型实例化 \n",
    "model = FCN(n_class)\n",
    "use_gpu = False\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN (\n",
       "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
       "  (relu1_1): ReLU (inplace)\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1_2): ReLU (inplace)\n",
       "  (pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_1): ReLU (inplace)\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_2): ReLU (inplace)\n",
       "  (pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_1): ReLU (inplace)\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_2): ReLU (inplace)\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_3): ReLU (inplace)\n",
       "  (pool3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_1): ReLU (inplace)\n",
       "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_2): ReLU (inplace)\n",
       "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_3): ReLU (inplace)\n",
       "  (pool4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5_1): ReLU (inplace)\n",
       "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5_2): ReLU (inplace)\n",
       "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5_3): ReLU (inplace)\n",
       "  (pool5): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (fc6): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (relu6): ReLU (inplace)\n",
       "  (drop6): Dropout2d (p=0.5)\n",
       "  (fc7): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (relu7): ReLU (inplace)\n",
       "  (drop7): Dropout2d (p=0.5)\n",
       "  (score_fr): Conv2d(4096, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (score_pool3): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (score_pool4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (upscore2): ConvTranspose2d(21, 21, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       "  (upscore8): ConvTranspose2d(21, 21, kernel_size=(16, 16), stride=(8, 8), bias=False)\n",
       "  (upscore_pool4): ConvTranspose2d(21, 21, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches = 100\n",
    "learning_rate = 0.001\n",
    "weight_decay=1e-4\n",
    "criterion = nn.NLLLoss2d()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IoU的值定义：(候选区域)Region Proposal与（标记区域）Ground Truth的窗口的交集比并集的比值，如果IoU低于0.5，那么相当于目标还是没有检测到\n",
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist\n",
    "\n",
    "def label_accuracy_score(label_trues, label_preds, n_class):\n",
    "    \"\"\"Returns accuracy score evaluation result.\n",
    "      - overall accuracy\n",
    "      - mean accuracy\n",
    "      - mean IU\n",
    "      - fwavacc\n",
    "    \"\"\"\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    \n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return acc, acc_cls, mean_iu, fwavacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#学习率的优化\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=30):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.5**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型的训练与测试\n",
    "def train_test(optimizer):\n",
    "    #训练\n",
    "    minibatch_y=[]\n",
    "    epoch_y=[]\n",
    "    epochacc_y=[]\n",
    "    wrong_all=[]\n",
    "    testacc_y=[]\n",
    "    testloss_y=[]\n",
    "    \n",
    "    for epoch in range(num_epoches):\n",
    "        print ('- - - - - epoch',epoch+1,'- - - - - - - -')\n",
    "        train_acc_cls = 0\n",
    "        epoch_mean_IoU = 0\n",
    "        train_fwavacc = 0\n",
    "        \n",
    "        batch_idx_sum = 0 \n",
    "        minibatch_loss=0\n",
    "        epoch_loss_sum=0\n",
    "        epoch_acc=0\n",
    "        \n",
    "        optimizer = exp_lr_scheduler(optimizer, epoch)\n",
    "        \n",
    "        for batch_idx, data in enumerate(trainloader , 1):\n",
    "            \n",
    "            batch_idx_sum += data[0].size()[0]\n",
    "            \n",
    "            if use_gpu:\n",
    "                im = Variable(data[0]).cuda()\n",
    "                label = Variable(data[1]).cuda()\n",
    "            else:\n",
    "                im = Variable(data[0])\n",
    "                label = Variable(data[1])\n",
    "            \n",
    "            out = model(im)\n",
    "\n",
    "            out = F.log_softmax(out) \n",
    "            print(out.size())\n",
    "            print(label.size())\n",
    "        \n",
    "            minibatch_loss = criterion(out, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            minibatch_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            #该列表存放每一个batch的loss值\n",
    "            minibatch_y.append(minibatch_loss.data[0])\n",
    "            \n",
    "            epoch_loss_sum += minibatch_loss.data[0]\n",
    "\n",
    "            label_pred = out.max(dim=1)[1].data.cpu().numpy()\n",
    "            \n",
    "            label_true = label.data.cpu().numpy()\n",
    "            \n",
    "            for lbt, lbp in zip(label_true, label_pred):\n",
    "                acc, acc_cls, mean_iu, fwavacc = label_accuracy_score(lbt, lbp, n_class)\n",
    "                epoch_acc += acc\n",
    "                train_acc_cls += acc_cls\n",
    "                epoch_mean_IoU += mean_iu\n",
    "                train_fwavacc += fwavacc\n",
    "                        \n",
    "            if batch_idx % 20 == 0 :\n",
    "                print(\"Train Epoch: {} [{}/{} ({:.0f}%)] ,Loss: {:.6f} ,Accuracy:{:.2f}%, Train Mean IoU:{:.5f}\".format(\n",
    "                    epoch+1,\n",
    "                    batch_idx_sum,\n",
    "                    len(train_data),\n",
    "                    100. * batch_idx_sum / len(train_data),\n",
    "                    minibatch_loss.data[0],\n",
    "                    100.*epoch_acc / batch_idx_sum,    \n",
    "                    epoch_mean_IoU / batch_idx_sum     \n",
    "                    ))\n",
    "                \n",
    "        epoch_loss_average = epoch_loss_sum/len(trainloader)\n",
    "\n",
    "        epoch_y.append(epoch_loss_average)\n",
    "        \n",
    "        epoch_acc_average=epoch_acc/len(train_data)\n",
    "\n",
    "        epochacc_y.append(epoch_acc_average)\n",
    "    #############################################################\n",
    "    #测试\n",
    "        model.eval()\n",
    "        step_sum = 0\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_acc_cls = 0\n",
    "        test_mean_IoU = 0\n",
    "        test_fwavacc = 0\n",
    "        for step, data in enumerate(testloader , 1):\n",
    "            \n",
    "            step_sum += data[0].size()[0]\n",
    "            \n",
    "            if use_gpu:\n",
    "                im = Variable(data[0], volatile=True).cuda()\n",
    "                label = Variable(data[1], volatile=True).cuda()\n",
    "            else:\n",
    "                im = Variable(data[0])\n",
    "                label = Variable(data[1])\n",
    "            \n",
    "            out = model(im)\n",
    "            out = F.log_softmax(out)\n",
    "            test_loss = criterion(out, label)\n",
    "            testloss_y.append(test_loss.data[0])\n",
    "\n",
    "            label_pred = out.max(dim=1)[1].data.cpu().numpy()\n",
    "            label_true = label.data.cpu().numpy()\n",
    "            \n",
    "            for lbt, lbp in zip(label_true, label_pred):\n",
    "                acc, acc_cls, mean_IoU, fwavacc = label_accuracy_score(lbt, lbp, n_class)\n",
    "                test_acc += acc\n",
    "                test_acc_cls += acc_cls\n",
    "                test_mean_IoU += mean_IoU\n",
    "                test_fwavacc += fwavacc\n",
    "        \n",
    "        testacc=test_acc/len(voc_test)\n",
    "        \n",
    "        test_mean_IoU = test_mean_IoU/len(voc_test)\n",
    "        \n",
    "        testacc_y.append(testacc)\n",
    "        \n",
    "        print(\"Test_accuracy: {:.2f}% , Test Mean IoU: {:.5f} \".format(100.*testacc, test_mean_IoU))\n",
    "    return minibatch_y, epoch_y, testloss_y, epochacc_y ,testacc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估\n",
    "train_start = time.time()\n",
    "minibatch_y, epoch_y, testloss_y, epochacc_y ,testacc_y = train_test(optimizer)\n",
    "train_stop = time.time()\n",
    "train_total = train_stop - train_start\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(train_total // 60, train_total % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型保存\n",
    "torch.save(model.state_dict(), './FCN_params.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果可视化处理\n",
    "cm = np.array(colormap).astype('uint8')\n",
    "def predict(im, label): # 预测结果\n",
    "    im = Variable(im.unsqueeze(0))\n",
    "    out = model(im)\n",
    "    pred = out.max(1)[1].squeeze().cpu().data.numpy()\n",
    "    pred = cm[pred]\n",
    "    return pred, cm[label.numpy()]\n",
    "_, figs = plt.subplots(5, 3, figsize=(12, 10))\n",
    "for i in range(5):\n",
    "    test_data, test_label = testdata[i]\n",
    "    pred, label = predict(test_data, test_label)\n",
    "    figs[i, 0].imshow(Image.open(testdata.data_list[i]))\n",
    "    figs[i, 0].axes.get_xaxis().set_visible(False)\n",
    "    figs[i, 0].axes.get_yaxis().set_visible(False)\n",
    "    figs[i, 1].imshow(label)\n",
    "    figs[i, 1].axes.get_xaxis().set_visible(False)\n",
    "    figs[i, 1].axes.get_yaxis().set_visible(False)\n",
    "    figs[i, 2].imshow(pred)\n",
    "    figs[i, 2].axes.get_xaxis().set_visible(False)\n",
    "    figs[i, 2].axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
